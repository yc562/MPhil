##### 1. dump_fastq #####

import os

import numpy  as np
import pandas as pd

annotation = pd.read_csv('./annotation.csv')

for col in annotation.columns:
    for idx in range(len(annotation[col])):
        sample_id = annotation.loc[idx,col]
        if not np.isnan(sample_id):
            run_accession = 2567177 + int(sample_id)
            for n in [1,2]:
                sample_code = f'S{int(sample_id)}_{n}'
                os.system(f'wget -m ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR256/ERR{run_accession}/{sample_code}.fastq.gz')
            
            if col == 'Control':
                os.system(f'mv ./ftp.sra.ebi.ac.uk/vol1/run/ERR256/ERR{run_accession} ~/Desktop/projectA/diseaseA/data/control')
            else:
                os.system(f'mv ./ftp.sra.ebi.ac.uk/vol1/run/ERR256/ERR{run_accession} ~/Desktop/projectA/diseaseA/data/disease')





##### 2. export_alleles #####

import os

import numpy  as np
import pandas as pd

###-----CONFIGURATION-----###

paired  = True
preset  = 'ampliseq-tcrb-plus-full-length'
species = 'hsa'
na_type = 'rna'

###-----------------------###

categories = os.listdir('./data/')

runs = dict()
for c in categories:
    runs[c] = os.listdir(f'./data/{c}/')

    for r in runs[c]:
        path = fr'./data/{c}/{r}/'
        alignment = fr'{path}{r}.vdjca'

        files = os.listdir(path)
        if '.listing' in files:
            os.system(f'rm {path}.listing')

        files = os.listdir(path)

        if paired:
            if len(files) == 2:
                input_1 = fr'{path}{files[0]}'
                input_2 = fr'{path}{files[1]}'

                print(f"Alignment for paired-end sequence files <{r}>.\n\n")
                os.system(fr'java –Xmx2g –Xms1g -jar ~/mixcr/mixcr.jar align -s {species} -p {preset} --{na_type} {input_1} {input_2} {alignment}')
        else:
            if len(files) == 1:
                input_1 = fr'{path}{files[0]}'

                print(f"Alignment for single-end sequence files <{r}>.\n\n")
                os.system(fr'java –Xmx2g –Xms1g -jar ~/mixcr/mixcr.jar align -s {species} -p {preset} --{na_type} {input_1} {alignment}')
        
        assemble = fr'{path}{r}.clns'
        alleles  = fr'{path}{r}_alleles.clns'

        eClones  = fr'{path}{r}_clns.tsv' 
        eAlleles = fr'{path}{r}_alleles.tsv'
        
        print(f"\n\nAssemble <{r}>.\n\n")
        os.system(fr'java –Xmx2g –Xms1g -jar ~/mixcr/mixcr.jar assemble {alignment} {assemble}')

        print(f"\n\nExport Clones <{r}_clns.tsv>.\n\n")
        os.system(fr'java –Xmx2g –Xms1g -jar ~/mixcr/mixcr.jar exportClones {assemble} {eClones}')

        print(f"\n\nExport Alleles Mutations <{r}_alleles.tsv>.\n\n")
        os.system(fr'java –Xmx2g –Xms1g -jar ~/mixcr/mixcr.jar findAlleles {assemble} --output-template {alleles} --export-alleles-mutations {eAlleles}')





##### merge_alleles #####
import os

import numpy  as np
import pandas as pd

categories = os.listdir('./data/')

runs,fAlleles = dict(),list()
for c in categories:
    runs[c] = os.listdir(f'./data/{c}/')

    for r in runs[c]:
        path  = fr'./data/{c}/{r}/'
        files = os.listdir(path)

        if str(f'{r}_alleles.tsv') in files:
            eAlleles = pd.read_csv(f'{path}{r}_alleles.tsv', delimiter='\t')

            for idx in range(len(eAlleles)):
                if type(eAlleles.loc[idx,'mutations']) == type(''):
                    allele_name = eAlleles.loc[idx,'geneName'] + '@' + eAlleles.loc[idx,'mutations']
                    fAlleles.append({'runs':r, 'alleleName':allele_name, 'type':eAlleles.loc[idx,'type'], 'category':c})

                else: pass

        else:
            print(f"'{r}_alleles.tsv' does not exist.")
            pass

fAlleles = pd.DataFrame(fAlleles)

fAlleles.to_csv("./result/fAlleles.csv",header=True)





##### alleleNo #####
import csv

# read original csv file
with open("fAlleles.csv") as original_file:
    reader = csv.reader(original_file)
    header = next(reader) # skip header row
    data = [row for row in reader]

# create a dictionary to store the simplified allele name
allele_dict = {}
counter = 1

# write to new csv file
with open("alleleNo.csv", "w", newline="") as new_file:
    writer = csv.writer(new_file)
    # write header row
    writer.writerow(header + ["geneName", "mutation", "alleleNo."])
    for row in data:
        allele_name = row[2]
        gene_name, mutation = allele_name.split("@")
        # check if the allele name has already been simplified
        if allele_name in allele_dict:
            allele_no = allele_dict[allele_name]
        else:
            allele_dict[allele_name] = allele_no = f"{gene_name}*({counter})"
            counter += 1
        writer.writerow(row + [gene_name, mutation, allele_no])





##### allele_count #####

import csv

# Read the original csv file
with open("alleleNo.csv", "r") as f:
    reader = csv.DictReader(f)
    data = [row for row in reader]

# Create a dictionary to store the count of each alleleNo. in control and disease groups
allele_count = {}
for row in data:
    alleleNo = row["alleleNo."]
    category = row["category"]
    if alleleNo not in allele_count:
        allele_count[alleleNo] = {"control": 0, "disease": 0}
    allele_count[alleleNo][category] += 1

# Calculate the allele percentages for control and disease
control_percentages = {}
disease_percentages = {}
for alleleNo, count in allele_count.items():
    control_percentages[alleleNo] = (count["control"] / 48) * 100
    disease_percentages[alleleNo] = (count["disease"] / 52) * 100

# Write the data to a new csv file
with open("allele_count.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["alleleNo.", "count in control", "count in disease", "allele percentage in control", "allele percentage in disease"])
    for alleleNo, count in allele_count.items():
        writer.writerow([alleleNo, count["control"], count["disease"], control_percentages[alleleNo], disease_percentages[alleleNo]])





##### double_barchart #####
import matplotlib.pyplot as plt
import csv

# Read the allele_count.csv file
with open("allele_count.csv", "r") as f:
    reader = csv.DictReader(f)
    data = [row for row in reader]

# Create lists to store the data for plotting
alleleNo_list = []
control_list = []
disease_list = []

# Extract only the alleleNo. starting with "IGHV"
for row in data:
    if row["alleleNo."].startswith("IGHV"):
        alleleNo_list.append(row["alleleNo."])
        control_list.append(float(row["allele percentage in control"]))
        disease_list.append(float(row["allele percentage in disease"]))

# Plot the bar chart
bar_width = 0.35
index = list(range(len(alleleNo_list)))

fig, ax = plt.subplots()
bar1 = ax.bar(index, control_list, bar_width, label="Control")
bar2 = ax.bar([i + bar_width for i in index], disease_list, bar_width, label="Disease")

ax.set_xlabel("AlleleNo")
ax.set_ylabel("Allele Percentage")
ax.set_xticks([i + bar_width / 2 for i in index])
ax.set_xticklabels(alleleNo_list, rotation=90)
ax.legend()

plt.tight_layout()
plt.show()





##### IGHVgeneusagefinal #####

import os
import numpy as np
import pandas as pd

categories = os.listdir('./data/')

# Create an empty data frame to store the results
results = pd.DataFrame(columns=["category", "Group", "readCount"])

for c in categories:
    runs = os.listdir(f'./data/{c}/')

    for r in runs:
        path  = fr'./data/{c}/{r}/'
        files = os.listdir(path)

        if str(f'{r}_clns_IGH.tsv') in files:

            # Load the data from the TSV file
            df = pd.read_csv(f'{path}{r}_clns_IGH.tsv', delimiter='\t')

            # Select the columns "readCount" and "allVHitsWithScore"
            df = df[["readCount", "allVHitsWithScore"]]

            # Group by the variable text before "-"
            df["Group"] = df["allVHitsWithScore"].str.split("*").str[0]

            # Add the "category" column
            df["category"] = c

            # Add up the readCount for each group
            df = df.groupby(["category", "Group"]).agg({"readCount": np.sum}).reset_index()

            # Concatenate the results to the overall data frame
            results = pd.concat([results, df], axis=0, ignore_index=True)

        else:
            print(f"'{r}_clns_IGH.tsv' does not exist.")
            pass

# Group by the variable text before "-"
results_grouped = results.groupby(["category", "Group"]).agg({"readCount": np.sum}).reset_index()

# Calculate the percentage readCount for each group within each category
results_grouped["percentage"] = results_grouped.groupby("category")["readCount"].apply(lambda x: x / x.sum() * 100)

# Save the new data frame to a new TSV file
results_grouped.to_csv("./result/IGHVgenefinal.tsv", sep='\t', index_label="Group")




